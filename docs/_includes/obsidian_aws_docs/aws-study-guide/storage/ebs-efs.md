- [Instance Storage](#instance-storage)
- [Amazon Elastic Block Store (EBS)](#amazon-elastic-block-store-ebs)
	- [Point-in-time EBS Snapshots](#point-in-time-ebs-snapshots)
	- [RAID](#raid)
		- [EBS Volume Status checks](#ebs-volume-status-checks)
	- [EBS Types](#ebs-types)
		- [EBS General purpose SSD](#ebs-general-purpose-ssd)
		- [EBS Provisioned IOPS SSD](#ebs-provisioned-iops-ssd)
		- [EBS Throughput Optimized HDD](#ebs-throughput-optimized-hdd)
		- [EBS Cold HDD](#ebs-cold-hdd)
		- [EBS Standard HDD (Legacy)](#ebs-standard-hdd-legacy)
- [Amazon Elastic File System (EFS)](#amazon-elastic-file-system-efs)
	- [EFS Types](#efs-types)
		- [General purpose performance mode](#general-purpose-performance-mode)
		- [MaxIO performance mode](#maxio-performance-mode)

# Instance Storage

It's a disk physically connected to the host.

The data is **lost** whenever you **stop** or **terminate** the instance, but **persists** if the instance **reboots.**

* Scope: **server** ()
* **Not persistent**
* **Low** latency
* **High** IOPS

Suggested for cache, buffers, scratch data and other temporary data.

AWS recommends keeping the **number of directories** on your file system to **less than 10,000**, if possible.


![service-logo](/assets/img/aws-icons/Arch_Amazon-Elastic-Block-Store_64.png)
# Amazon Elastic Block Store (EBS)

EBS volumes are automatically replicated in the **same AZ** of the EC2.

EBS volumes can be **encrypted** using industry-standard AES-256 keys generated by AWS KMS.

* Scope: **AZ**
* Availability **5** 9s
* Durability **.1**% to **.2**%

## EBS Snapshots

To increase durability you can use PIT Snapshots, that are replicated across **multiple AZs** in the region. These sanpshots can be used to **create new volumes**.

If there’s an accidental delete or other application error, snapshots enable you to recover your data.
* Scope: **Region** (S3)
* Availability **4** 9s (S3)
* Durability **11** 9s (S3)
* To increase resilience = custom solution multi backup, multi region, multi account

- Snapshots that are taken from encrypted volumes are automatically encrypted
- Volumes that are created from encrypted snapshots are also automatically encrypted
-  To share an encrypted snapshot:
	- You must also share the CMK key that was used to encrypt it
	- External users must create their own personal copy of it and then use that copy

When you create an EBS volume from a snapshot, data is **lazy loaded** into the volume, meaning that if the volume is accessed where data is not loaded, the application encounters a higher latency than normal.

### EBS Snapshots Archive
Low-cost, long-term storage tier for rarely-accessed snapshots.

When you archive a snapshot, the incremental snapshot is **converted to a full snapshot**, and it is moved from the standard tier to the Amazon EBS Snapshots Archive tier.

When you need to access an archived snapshot, you can **restore** it from the archive tier to the standard tier, and **then use it** in the same way that you use any other snapshot in your account.

### Multi-volume snapshots
- Point-in-time snapshots for all, or some, of the volumes attached to an instance
- Each snapshot is treated as an individual snapshot
- Multi-volume, crash-consistent snapshots are typically restored as a set
- It's a good idea to identify the snapshots that are in a crash-consistent set by tagging them with the instance ID, name, or other relevant details

### EBS Data Lifecycle Manager (DLM)
Provides a simple, automated way to back up data stored on Amazon EBS volumes.
- **Automated snapshot and AMI creation**
- **Fast snapshot restore integration**
	  Restore volumes that are fully initialized at creation
- **Built-in cross-Region copy**
- **Automated cross-account snapshot copy**
## RAID
EBS Striped volume = Raid 0\
EBS Mirror = Raid 1

### EBS Volume Status checks

* Any volume type
  * ok
  * warning
  * impaired
  * insufficient data
* Provisioned IOPS SSD
  * Normal
  * Degraded
  * Stalled
  * Insufficient data



## EBS Types

### SSD-based volumes - General purpose
Balance price and performance, recommended for most workloads.

|  | gp2 | gp3 |
| ---- | ---- | ---- |
| Use cases | Boot volumes, <br>low-latency interactive apps, <br>dev & test | as gp2 + <br>medium sized <br>single instance databases |
| Volume size | 1 GB – 16 TB | '' |
| Durability | 99.8% - 99.9% | '' |
| Baseline IOPS | 3 IOPS/GB<br>(minimum 100 IOPS) | 3,000 IOPS at any size |
| Max IOPS/volume | 16,000 | '' |
| Burst | up to 3,000 IOPS | no burst |
| Max Throughput/volume | 250 MB/s | 1000 MB/s |
| Max IOPS/Instance | 260,000 | '' |
| Max Throughput/Instance | 7,500 MB/s | 12,500 MB/s |
| Latency | single digit ms | '' |
| Price (GB/month) | $0.10 | $0.08 |
| Dominant performance attribute | IOPS | $/IOPS |

### SSD-based volumes - High performance
Highest performance, for mission-critical low-latency or high throughput workloads (large databases).

|  | io1 | io2 Block Express |
| ---- | ---- | ---- |
| Use cases | I/O-intensive<br>NoSQL & <br>relational databases | business-critical <br>'' |
| Volume size | 4 GB – 16 TB | 4 GB – 64 TB |
| Durability | 99.8% - 99.9% | 99.999% |
| Max IOPS/volume | 64,000 | 256,000 |
| Max Throughput/volume | 1,000 MB/s | 4,000 MB/s |
| Max IOPS/Instance | 400,000 | '' |
| Max IOPS/GB | 50 IOPS/GB | 1,000 IOPS/GB |
| Max Throughput/Instance | 12,500 MB/s | '' |
| Latency | single digit ms | sub-millisecond |
| Price (GB/month) | $0.125 | $0.125 |
| Price (Provisioned IOPS-month) | $0.065 | $0.065 (first 32,000)<br>$0.046 (32,001 to 64,000 IOPS)<br>$0.032 (greater than 64,000 IOPS) |
| Dominant performance attribute | IOPS | IOPS, throughput, latency, <br>capacity, and volume durability |

### HDD-based volumes
Lowest cost volumes, for less frequently accessed workloads. 

|  | sc1<br>Cold HDD | st1<br>Throughput optimized HDD |
| ---- | ---- | ---- |
| Use cases | Colder data <br>requiring<br>fewer scans per day | Big data, <br>data warehouses, <br>log processing |
| Volume size | 125 GB – 16 TB | '' |
| Durability | 99.8% - 99.9% | '' |
| Max IOPS/volume | 250 | 500 |
| Baseline throughput | 12 MB/s per TB | 40 MB/s per TB |
| Max Throughput/volume | 250 MB/s | 500 MB/s |
| Burst | up to 80 MB/s per TB | up to 250 MB/s per TB |
| Max Throughput/Instance | 7,500 MB/s | 12,500 MB/s |
| Latency | single digit ms |  |
| Price (GB/month) | $0.015 | $0.045 |
| Dominant performance attribute | MB/s | '' |


## EBS Multi-Attach
Multi-Attach makes it easier to achieve higher application availability in applications that manage concurrent write operations. You can enable Multi-Attach during volume creation.
- Works only with `io1` or `io2` volumes
- Instances must be in the same AZ
- Each instance has full read/write permission
- Standard file systems, such as XFS and EXT4, are not designed to be accessed simultaneously by multiple servers. You should use a clustered file system to ensure data resiliency and reliability for your production workloads.
- Multi-Attach enabled volumes can't be created as boot volumes

## EBS Elastic Volumes
You can increase the volume size, change the volume type, or adjust the performance of your volume without detaching it or restarting the instance. This enables you to continue using your application while the changes take effect. There is no charge to modify the configuration of a volume.
- Supported by all current generation instances, and some of previous ones
- After modifying a volume, you must wait at least **6 hours**
- The change can take from a **few minutes** to a **few hours**, depending on the configuration changes being applied. The time it takes for volumes to be modified doesn't always scale linearly.


![service-logo](/assets/img/aws-icons/Arch_Amazon-EFS_64.png)
# Amazon Elastic File System (EFS)

Simple, scalable elastic file system for linux that can be mounted **concurrently** through NFSv4.

* Scope: **Region**
* Availability: **3** 9s ---> Lower availability than EBS
* Durability: **11** 9s ---> Higher durability than EBS
* Replicato in modo sincrono in due istanze nella AZ
* Up to **3GB**/s throughput (in some regions is 1GB/s)
* 250MB/s per client
* Latency: unpublished but can be 1ms

Tenere d'occhio la metrica di **BurstIO**, se scende a zero per un alto numero di client ci sarà un crollo delle prestazioni.

## EFS Types

### General purpose performance mode

* **7000** IOPS
* **Lowest** metadata latency

### MaxIO performance mode

* **500.000+** IOPS
* **Highest** metadata latency



Performance is impacted by:
- **File system type** – Regional or One Zone
- **Performance mode** – General Purpose or Max I/O (General Purpose gives faster performance!)
- **Throughput mode** – Elastic, Provisioned, or Bursting

## Storage classes

- **EFS Standard**
   - Uses solid state drive (SSD) storage to deliver the lowest levels of latency for frequently accessed files
   - Provides first-byte latencies as low as **250us for reads** and **2.7ms for writes**.

- **EFS Infrequent Access (IA)** and **EFS Archive** 
	- Less frequently accessed data that doesn't require great latency performance 
	- Provide first-byte latencies of **tens of milliseconds**.

## Performance modes

- **General Purpose mode**
	- Lowest per-operation latency
	- Default performance mode for file systems
	- One Zone file systems always use the General Purpose performance mode.
	- Recommended for faster performance
    
- **Max I/O mode**
	- Previous generation performance type
	- Designed for highly parallelized workloads that can tolerate higher latencies
	- Not supported for One Zone file systems or file systems that use Elastic throughput

## Throughput modes

Your file system can achieve a **combined 100%** of its read and write throughput.
- For example:
	- if your file system is using 33% of its read throughput limit
	- the file system can simultaneously achieve up to 67% of its write throughput limit. 

- **Elastic throughput** (Recommended)
	- Default
	- When you have performance requirements that are difficult to forecast
	- When your application drives throughput at an average-to-peak ratio of **5% or less**
    
- **Provisioned throughput**
	- When you know your workload's performance requirements
	- When your application drives throughput at an average-to-peak ratio of **5% or more**
    
- **Bursting throughput**
	- When you want throughput that scales with the amount of storage in your file system